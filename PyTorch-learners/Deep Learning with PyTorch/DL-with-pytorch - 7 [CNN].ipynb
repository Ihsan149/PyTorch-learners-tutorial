{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL-with-pytorch - 7 [CNN].ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"bIAYbYajk1w9","colab_type":"text"},"cell_type":"markdown","source":["# Convolutional Neural Networks\n","- IMDB review sentiment classification with CNN\n","  - Last time, we have started sentence classification with CNN having only one filter. Here, let's try more complicated CNN architecture with different filter sizes to ameliorate the performance."]},{"metadata":{"id":"GVU5-yp3N89I","colab_type":"code","outputId":"9e427acb-6e7c-46f8-ccbc-61a5b071edd2","executionInfo":{"status":"ok","timestamp":1545932184206,"user_tz":420,"elapsed":66823,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":336}},"cell_type":"code","source":["!pip3 install torch torchvision"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting torch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n","\u001b[K    100% |████████████████████████████████| 591.8MB 28kB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x61d2e000 @  0x7f29476992a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n","\u001b[?25hCollecting torchvision\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 18.0MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Collecting pillow>=4.1.1 (from torchvision)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n","Installing collected packages: torch, pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.3.0 torch-1.0.0 torchvision-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"8yy37hEYOEiQ","colab_type":"code","outputId":"3ba43d71-c184-412a-ac18-f18c1b5ccf78","executionInfo":{"status":"ok","timestamp":1545933745335,"user_tz":420,"elapsed":1595,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch, torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","torch.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.0.0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"ewrw93tt2BfV","colab_type":"text"},"cell_type":"markdown","source":["## 1. Import & process dataset\n","- IMDB review dataset for sentiment analysis\n","  - [source](http://ai.stanford.edu/~amaas/data/sentiment/)\n","  - Let's cheat a while and use dataset provided by Keras"]},{"metadata":{"id":"SxDHXFEsf5em","colab_type":"code","outputId":"e48ae898-fb20-421d-abf4-088ff78e5c6c","executionInfo":{"status":"ok","timestamp":1545933757212,"user_tz":420,"elapsed":13458,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["from keras.datasets import imdb\n","from keras.preprocessing import sequence\n","\n","num_words = 10000\n","maxlen = 50\n","\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = num_words)\n","\n","X_train = sequence.pad_sequences(X_train, maxlen = maxlen, padding = 'pre')\n","X_test = sequence.pad_sequences(X_test, maxlen = maxlen, padding = 'pre')\n","    \n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["(25000, 50) (25000, 50) (25000,) (25000,)\n"],"name":"stdout"}]},{"metadata":{"id":"9nznVMdo5edZ","colab_type":"text"},"cell_type":"markdown","source":["## 2. Creating CNN model and training\n","\n","- Create and train CNN model for sentence classification, with three convolutional & max pooling layers concatenated in the end.\n","- Model architecture is adopted from [Kim 2015](https://www.aclweb.org/anthology/D14-1181)\n","\n","![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Example-of-a-CNN-Filter-and-Polling-Architecture-for-Natural-Language-Processing.png)"]},{"metadata":{"id":"tdmsy2B3weeK","colab_type":"code","colab":{}},"cell_type":"code","source":["class imdbTrainDataset(torch.utils.data.Dataset):\n","  def __init__(self):\n","    self.X = X_train\n","    self.y = y_train\n","  \n","  def __getitem__(self, idx):\n","    return self.X[idx], self.y[idx]\n","  \n","  def __len__(self):\n","    return len(self.X)\n","  \n","class imdbTestDataset(torch.utils.data.Dataset):\n","  def __init__(self):\n","    self.X = X_test\n","    self.y = y_test\n","  \n","  def __getitem__(self, idx):\n","    return self.X[idx], self.y[idx]\n","  \n","  def __len__(self):\n","    return len(self.X)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xFBmmDxKw1t2","colab_type":"code","colab":{}},"cell_type":"code","source":["# create dataset & dataloader instances\n","train_dataset = imdbTrainDataset()\n","test_dataset = imdbTestDataset()\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 128, shuffle = False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AQawpMRPI7jm","colab_type":"code","colab":{}},"cell_type":"code","source":["# create CNN with one convolution/pooling layer\n","class net(nn.Module):\n","  def __init__(self, input_dim, num_words, embedding_dim, num_filters, kernel_size, stride):\n","    super(net, self).__init__()\n","    self.input_dim = input_dim\n","    self.embedding_dim = embedding_dim\n","    \n","    conv_output_size1 = int((input_dim - kernel_size[0])/stride) + 1   # first conv layer output size\n","    conv_output_size2 = int((input_dim - kernel_size[1])/stride) + 1   # first conv layer output size\n","    conv_output_size3 = int((input_dim - kernel_size[2])/stride) + 1   # first conv layer output size\n","        \n","    self.embedding = nn.Embedding(num_words, self.embedding_dim)\n","    \n","    # three convolution & pooling layers\n","    self.conv1 = nn.Conv2d(1, num_filters[0], kernel_size = (kernel_size[0], self.embedding_dim), stride = stride)     \n","    self.pool1 = nn.MaxPool2d((conv_output_size1, 1))                # Max-over-time pooling\n","    self.conv2 = nn.Conv2d(1, num_filters[1], kernel_size = (kernel_size[1], self.embedding_dim), stride = stride)     \n","    self.pool2 = nn.MaxPool2d((conv_output_size2, 1))                # Max-over-time pooling\n","    self.conv3 = nn.Conv2d(1, num_filters[2], kernel_size = (kernel_size[2], self.embedding_dim), stride = stride)     \n","    self.pool3 = nn.MaxPool2d((conv_output_size3, 1))                # Max-over-time pooling\n","    \n","    self.relu = nn.ReLU()\n","    self.dense = nn.Linear(num_filters[0] + num_filters[1] + num_filters[2], 2)     \n","    \n","  def forward(self, x):\n","    x = self.embedding(x)                                   # project to word embedding space\n","    x = x.view(-1, 1, self.input_dim, self.embedding_dim)   # resize to fit into convolutional layer\n","    x1 = self.pool1(self.relu(self.conv1(x)))\n","    x2 = self.pool2(self.relu(self.conv2(x)))\n","    x3 = self.pool3(self.relu(self.conv3(x)))\n","\n","    x = torch.cat((x1, x2, x3), dim = 1)   # concatenate three convolutional outputs\n","    x = x.view(x.size(0), -1)   # resize to fit into final dense layer\n","    x = self.dense(x)\n","    return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rP0Gt5E9ajmd","colab_type":"code","colab":{}},"cell_type":"code","source":["# hyperparameters\n","DEVICE = torch.device('cuda')\n","INPUT_DIM = maxlen\n","NUM_FILTERS = (16, 32, 64) \n","KERNEL_SIZE = (1, 2, 3)\n","STRIDE = 1\n","EMBEDDING_DIM = 50\n","NUM_WORDS = num_words\n","LEARNING_RATE = 1e-3\n","NUM_EPOCHS = 30         "],"execution_count":0,"outputs":[]},{"metadata":{"id":"cPBm8qDrSWsi","colab_type":"code","colab":{}},"cell_type":"code","source":["model = net(INPUT_DIM, NUM_WORDS, EMBEDDING_DIM, NUM_FILTERS, KERNEL_SIZE, STRIDE).to(DEVICE)\n","criterion = nn.CrossEntropyLoss()   # do not need softmax layer when using CEloss criterion\n","optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SEBtAPYCFeic","colab_type":"code","outputId":"ed0ebe28-62f1-4e8d-e464-d66cdb3d49cb","colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1545934527865,"user_tz":420,"elapsed":224951,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}}},"cell_type":"code","source":["# training for NUM_EPOCHS\n","for i in range(NUM_EPOCHS):\n","  temp_loss = []\n","  for (x, y) in train_loader:\n","    x, y = x.long().to(DEVICE), y.to(DEVICE)  # beware that input to embedding should be type 'long'\n","    outputs = model(x)\n","    loss = criterion(outputs, y)\n","    temp_loss.append(loss.item())\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","  print(\"Loss at {}th epoch: {}\".format(i, np.mean(temp_loss)))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Loss at 0th epoch: 0.6226605290965158\n","Loss at 1th epoch: 0.4895881914666721\n","Loss at 2th epoch: 0.40360755549401656\n","Loss at 3th epoch: 0.3413624836474049\n","Loss at 4th epoch: 0.2855290376714298\n","Loss at 5th epoch: 0.23665862393622494\n","Loss at 6th epoch: 0.19332292257827155\n","Loss at 7th epoch: 0.1526499463587391\n","Loss at 8th epoch: 0.11854718325241488\n","Loss at 9th epoch: 0.09007945675783012\n","Loss at 10th epoch: 0.06637739711346066\n","Loss at 11th epoch: 0.04888947682493195\n","Loss at 12th epoch: 0.03602837147761365\n","Loss at 13th epoch: 0.026454947622759\n","Loss at 14th epoch: 0.019765267642785092\n","Loss at 15th epoch: 0.015103718741055655\n","Loss at 16th epoch: 0.011833845148319188\n","Loss at 17th epoch: 0.00931674547075313\n","Loss at 18th epoch: 0.007469219165112899\n","Loss at 19th epoch: 0.006082932326980695\n","Loss at 20th epoch: 0.005003999198824927\n","Loss at 21th epoch: 0.004151264236460687\n","Loss at 22th epoch: 0.0034760919789194452\n","Loss at 23th epoch: 0.0029148718803094662\n","Loss at 24th epoch: 0.002471668743148294\n","Loss at 25th epoch: 0.0021142353920256527\n","Loss at 26th epoch: 0.0018004027156073752\n","Loss at 27th epoch: 0.0015497613752888022\n","Loss at 28th epoch: 0.001329448939495891\n","Loss at 29th epoch: 0.001152327883518206\n"],"name":"stdout"}]},{"metadata":{"id":"qpAJUiHm529m","colab_type":"text"},"cell_type":"markdown","source":["## 3. Evaluation\n","- Evaluate the trained CNN model with accuracy score \n","  - Store probability of each instance to a list and compare it with true y label"]},{"metadata":{"id":"txXH3dknFpSx","colab_type":"code","outputId":"eb7f5d0b-a845-49b4-f7b8-f93b536c30a3","executionInfo":{"status":"ok","timestamp":1545935074996,"user_tz":420,"elapsed":1243,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["y_pred, y_true = [], []\n","with torch.no_grad():\n","  for x, y in test_loader:\n","    x, y = x.long().to(DEVICE), y.to(DEVICE)       # beware that input to embedding should be type 'long'\n","    outputs = F.softmax(model(x)).max(1)[-1]       # predicted label\n","    y_true += list(y.cpu().numpy())                # true label\n","    y_pred += list(outputs.cpu().numpy())   "],"execution_count":28,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  \"\"\"\n"],"name":"stderr"}]},{"metadata":{"id":"HV1s3xf5Frkl","colab_type":"code","outputId":"73dc11cb-5863-4e41-f9f8-29ee06fc7c02","executionInfo":{"status":"ok","timestamp":1545935076195,"user_tz":420,"elapsed":1299,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# evaluation result\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_true, y_pred)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.80096"]},"metadata":{"tags":[]},"execution_count":29}]}]}