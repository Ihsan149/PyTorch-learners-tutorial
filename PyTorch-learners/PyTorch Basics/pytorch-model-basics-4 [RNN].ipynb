{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch-model-basics-4 [RNN].ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"bIAYbYajk1w9","colab_type":"text"},"cell_type":"markdown","source":["# Recurrent Neural Networks\n","- Vanilla RNN\n","- Gated Recurrent Units\n","- Long Short Term Memory"]},{"metadata":{"id":"GVU5-yp3N89I","colab_type":"code","outputId":"cf6476e7-6200-49b3-988b-2d06b766f76f","executionInfo":{"status":"ok","timestamp":1544639936834,"user_tz":420,"elapsed":62712,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":336}},"cell_type":"code","source":["!pip3 install torch torchvision"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting torch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n","\u001b[K    100% |████████████████████████████████| 591.8MB 24kB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x60d92000 @  0x7f44731162a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n","\u001b[?25hCollecting torchvision\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 21.9MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Collecting pillow>=4.1.1 (from torchvision)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n","Installing collected packages: torch, pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.3.0 torch-1.0.0 torchvision-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"8yy37hEYOEiQ","colab_type":"code","outputId":"2d1d0d0a-874a-4e70-bc06-02e695726b41","executionInfo":{"status":"ok","timestamp":1544646625339,"user_tz":420,"elapsed":1221,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch, torchvision\n","torch.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.0.0'"]},"metadata":{"tags":[]},"execution_count":37}]},{"metadata":{"id":"gyv2Sy5WO8lK","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.nn as nn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XoCXfOh1RQun","colab_type":"text"},"cell_type":"markdown","source":["## 1. Vanilla RNN\n","![vanilla_RNN](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n","\n","\n","- Vanilla RNN can be implemented with ```torch.nn.RNN()``` \n","\n","- Key Parameters\n","  - ```input_size```:  number of expected features in the input (i.e., dimensionality of feature space)\n","  - ```hidden_size```: number of features in hidden state (i.e., dimensionality of output space)\n","  - ```num_layers```: number of recurrent layers (to create stacked RNN)\n","  - ```batch_first```: If ```True```, input and output tensor shapes are ```(batch_size, seq_length, dim_feature)```. If ```False```, ```(sequence_length, batch_size, dim_feature)```\n","  - ```bidirectional```: If ```True```, bidirectional RNN\n","  \n","- One thing to note is that unlike fully-connected layers or convolutional layers, RNNs take multi inputs/outputs\n","  - In addition to (sequential) inputs, RNN has another called hidden state, which makes RNN special\n","  - This hidden state sends information regarding current step to the next\\\n","  \n","- Inputs to RNN: ```(x0, h0)```\n","  - ```x0```: tensor that contains features of the input sequence\n","    - shape\n","      - ```(seq_len, batch_size, input_size)``` if ```batch_first == False``` (default)\n","      - ```(batch_size, seq_len, input_size)``` if ```batch_fist == True``` \n","  - ```h0```: tensor that contains hidden state for each instance\n","    - shape\n","      - ```(num_layers * num_directions, batch_size, hidden_size)```"]},{"metadata":{"id":"kp_YDg0aQQ0e","colab_type":"code","colab":{}},"cell_type":"code","source":["rnn = nn.RNN(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rtVnd-SJomFA","colab_type":"code","outputId":"4e2aaebc-fe5a-4946-b082-a84390d38312","executionInfo":{"status":"ok","timestamp":1544646557492,"user_tz":420,"elapsed":1030,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["## inputs to RNN\n","# input data (seq_len, batch_size, input_size)\n","x0 = torch.from_numpy(np.random.randn(12, 64, 10)).float()     \n","# hidden state (num_layers * num_directions, batch_size, hidden_size)\n","h0 = torch.from_numpy(np.zeros((1, 64, 5))).float()            \n","\n","print(x0.shape, h0.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([12, 64, 10]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"metadata":{"id":"fDyuMNs9oyQ-","colab_type":"code","outputId":"398e326a-c805-4c69-bd13-2d894224100d","executionInfo":{"status":"ok","timestamp":1544647163096,"user_tz":420,"elapsed":1503,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["## outputs from RNN\n","# output (seq_len, batch_size, num_directions * hidden_size)\n","# hidden state (num_layers * num_directions, batch_size, hidden_size)\n","out, h1 = rnn(x0, h0)\n","\n","print(out.shape, h1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([12, 64, 5]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"metadata":{"id":"LMcGMyJNSzSA","colab_type":"code","colab":{}},"cell_type":"code","source":["# when batch_first = True\n","rnn = nn.RNN(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 2,     # stacked RNN (2 layers)\n","             batch_first = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1wKPW7qiWZJt","colab_type":"code","outputId":"a84dc940-c6ee-4e42-a195-a781f6c1971b","executionInfo":{"status":"ok","timestamp":1544647225067,"user_tz":420,"elapsed":1061,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["## inputs to RNN\n","x0 = torch.from_numpy(np.random.randn(64, 12, 10)).float()     \n","# note that even batch_first == True, hidden state shape order does not change\n","h0 = torch.from_numpy(np.zeros((2, 64, 5))).float()            \n","\n","print(x0.shape, h0.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([64, 12, 10]) torch.Size([2, 64, 5])\n"],"name":"stdout"}]},{"metadata":{"id":"aqUXKwvIXUH-","colab_type":"code","outputId":"81931e92-f228-4de7-ea64-50eb37f16ad4","executionInfo":{"status":"ok","timestamp":1544647249382,"user_tz":420,"elapsed":1058,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["## outputs from RNN\n","out, h1 = rnn(x0, h0)\n","\n","print(out.shape, h1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([64, 12, 5]) torch.Size([2, 64, 5])\n"],"name":"stdout"}]},{"metadata":{"id":"E4AJ3I9JWnyZ","colab_type":"code","outputId":"952ac553-5608-4888-eafd-ccef2d44dfe6","executionInfo":{"status":"ok","timestamp":1544647257247,"user_tz":420,"elapsed":1064,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# bidirectional, stacked RNN\n","rnn = nn.RNN(input_size = 20, \n","             hidden_size = 10, \n","             num_layers = 4,     \n","             bidirectional = True)\n","\n","x0 = torch.from_numpy(np.random.randn(5, 64, 20)).float()\n","h0 = torch.from_numpy(np.zeros((4 * 2, 64, 10))).float()  # notice the dimensionality of hidden state\n","out, h1 = rnn(x0, h0)\n","\n","print(out.shape, h1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([5, 64, 20]) torch.Size([8, 64, 10])\n"],"name":"stdout"}]},{"metadata":{"id":"7jJnvcgAXpSq","colab_type":"text"},"cell_type":"markdown","source":["## 2. Gated Recurrent Units (GRU)\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Gated_Recurrent_Unit%2C_base_type.svg/780px-Gated_Recurrent_Unit%2C_base_type.svg.png)\n","\n","- GRU has rather complicated structure compared to vanilla RNN (see below figure), but in terms of implementing it with Pytorch, largely similar to RNN, using ```torch.nn.GRU```"]},{"metadata":{"id":"Irn1yF5lb3HO","colab_type":"code","colab":{}},"cell_type":"code","source":["gru = nn.GRU(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ddO_D_L2b81J","colab_type":"code","outputId":"ec9c2336-aace-441d-9acb-42506c482c65","executionInfo":{"status":"ok","timestamp":1544640247042,"user_tz":420,"elapsed":1663,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["## inputs to GRU\n","# input data (seq_len, batch_size, input_size)\n","x0 = torch.from_numpy(np.random.randn(12, 64, 10)).float()     \n","# hidden state (num_layers * num_directions, batch_size, hidden_size)\n","h0 = torch.from_numpy(np.zeros((1, 64, 5))).float()            \n","\n","print(x0.shape, h0.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([12, 64, 10]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"metadata":{"id":"ukQSVR0yY2VC","colab_type":"code","outputId":"b98de175-9c9a-4297-ab94-e7808a25f1da","executionInfo":{"status":"ok","timestamp":1544640247498,"user_tz":420,"elapsed":1021,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["## outputs from GRU\n","# output (seq_len, batch_size, num_directions * hidden_size)\n","# hidden state (num_layers * num_directions, batch_size, hidden_size)\n","out, h1 = gru(x0, h0)\n","\n","print(out.shape, h1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([12, 64, 5]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"metadata":{"id":"MaM0ruFEtlQA","colab_type":"text"},"cell_type":"markdown","source":["## 3. Long Short Term Memory (LSTM)\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/1200px-The_LSTM_cell.png)\n","\n","- LSTM is another variant of vanilla RNN that is widely used. Though there exist some differences in structure, when implementing one just need to attend to the cell state (c_t)\n","  - Inputs to LSTM: (x0, (h0, c0)\n","    - ```x0```: tensor that contains features of the input sequence\n","      - shape: ```(seq_len, batch_size, input_size)```\n","    - ```h0```: tensor that contains initial hidden state\n","      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```\n","    - ```c0```: tensor that contains initial cell state\n","      - shape: ```(num_layers * num_directions, batch_size, hidden_size)``` (same as h0)\n","  - Outputs to LSTM: (xn, (hn, cn))\n","    - ```xn```: tensor that contains output features from the last layer\n","      - shape: ```(seq_len, batch_size, num_directions * hidden_size)```\n","    - ```hn```: tensor containing the hidden state\n","      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```\n","    - ```cn```: tensor containing the cell state\n","      - shape: ```(num_layers * num_directions, batch_size, hidden_size)```"]},{"metadata":{"id":"LSUeaLXatsK-","colab_type":"code","colab":{}},"cell_type":"code","source":["lstm = nn.LSTM(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uOcAQRqSt826","colab_type":"code","outputId":"3bd8e411-0d5b-4ad1-9da5-daa7ba78a139","executionInfo":{"status":"ok","timestamp":1544647697084,"user_tz":420,"elapsed":588,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["## inputs to LSTM\n","# input data (seq_len, batch_size, input_size)\n","x0 = torch.from_numpy(np.random.randn(1, 64, 10)).float()     \n","\n","print(x0.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 64, 10])\n"],"name":"stdout"}]},{"metadata":{"id":"iVEKLB3xLWAR","colab_type":"code","outputId":"00d14088-7077-4262-a068-832ad811493b","executionInfo":{"status":"ok","timestamp":1544647738377,"user_tz":420,"elapsed":923,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["# outputs from LSTM\n","# when initial hidden & cell state are not given, they are regarded as zero\n","xn, (hn, cn) = lstm(x0)\n","\n","print(xn.shape)               # (seq_len, batch_size, hidden_size)\n","print(hn.shape, cn.shape)     # (num_layers, batch_size, hidden_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 64, 5])\n","torch.Size([1, 64, 5]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"metadata":{"id":"uNiSC9sPLf_w","colab_type":"code","outputId":"1c8c0dc3-0892-44fe-ab7d-f625ac51d393","executionInfo":{"status":"ok","timestamp":1544647909318,"user_tz":420,"elapsed":1511,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["# when initial hidden & cell states are given\n","x0 = torch.from_numpy(np.random.randn(1, 64, 10)).float()     \n","h0, c0 = torch.from_numpy(np.zeros((1, 64, 5))).float(), torch.from_numpy(np.zeros((1, 64, 5))).float()\n","\n","xn, (hn, cn) = lstm(x0, (h0, c0))\n","\n","print(xn.shape)               # (seq_len, batch_size, hidden_size)\n","print(hn.shape, cn.shape)     # (num_layers, batch_size, hidden_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 64, 5])\n","torch.Size([1, 64, 5]) torch.Size([1, 64, 5])\n"],"name":"stdout"}]},{"metadata":{"id":"7uiNzfCkuhHu","colab_type":"code","colab":{}},"cell_type":"code","source":["# stacked, bidirectional LSTM\n","lstm = nn.LSTM(input_size = 10, \n","             hidden_size = 5, \n","             num_layers = 2,\n","             bidirectional = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3SLQllzOMhEN","colab_type":"code","outputId":"20d4d277-e0d0-42aa-c9bb-d3b1fdc6c9e6","executionInfo":{"status":"ok","timestamp":1544648053540,"user_tz":420,"elapsed":1543,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["# inputs to LSTM\n","x0 = torch.from_numpy(np.random.randn(5, 64, 10)).float()\n","h0, c0 = torch.from_numpy(np.zeros((4, 64, 5))).float(), torch.from_numpy(np.zeros((4, 64, 5))).float()\n","\n","xn, (hn, cn) = lstm(x0, (h0, c0))\n","\n","print(xn.shape)\n","print(hn.shape, cn.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([5, 64, 10])\n","torch.Size([4, 64, 5]) torch.Size([4, 64, 5])\n"],"name":"stdout"}]}]}